{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXFAys9md8Eo"
      },
      "source": [
        "# NIH Chest X-ray Classification using Hierarchical Vision Transformers\n",
        "## Matthew Ohanian\n",
        "\n",
        "This notebook implements a hierarchical approach to chest X-ray classification using two Vision Transformer (ViT) models:\n",
        "1. A binary classifier that determines if an X-ray contains any pathological finding\n",
        "2. A multi-label classifier that identifies specific pathological conditions only when the binary classifier detects a finding\n",
        "\n",
        "This approach mimics radiologist workflow (first detecting abnormality, then characterizing it) and might improve performance by specializing each model for its specific task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzzOaTM-d8Ep",
        "outputId": "bfc98203-581d-4868-8d0f-f0fc9e114cc0"
      },
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Import custom modules\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/deep_learning_proj/')\n",
        "\n",
        "# Import NIH dataset module\n",
        "import NIH_ChestXRay_Dataset_Module as nih\n",
        "\n",
        "# Import custom modules for hierarchical ViT models\n",
        "import nih_hierarchical_vit as nih_hvit"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Data Preprocessing (5%)\n",
        "\n",
        "## 1.1 Dataset Overview\n",
        "\n",
        "The NIH Chest X-ray dataset is a large public dataset of chest X-rays containing 14 common thoracic pathologies. Each image can have multiple labels, making this a multi-label classification problem. The dataset also includes a \"No Finding\" label indicating the absence of pathological conditions.\n",
        "\n",
        "## 1.2 Data Loading and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JgP08And8Eq",
        "outputId": "f086f127-1bfa-4b1f-cf4a-da1f7efc1309"
      },
      "source": [
        "# Data Loading\n",
        "data_dir = \"/content/drive/MyDrive/deep_learning_proj/data/nih_data\"\n",
        "train_loader, val_loader, test_loader, class_weights = nih.get_nih_data_loaders(\n",
        "    data_dir=data_dir,\n",
        "    batch_size=128,\n",
        "    sample_size=500,  # Adjust sample size as needed\n",
        "    test_size=100,\n",
        "    balance=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Get disease labels (excluding \"No Finding\")\n",
        "disease_labels = [label for label in nih.NIHChestXRay.LABELS if label != \"No Finding\"]\n",
        "print(f\"Disease labels: {disease_labels}\")\n",
        "\n",
        "# Visualize class distribution\n",
        "def count_labels(loader):\n",
        "    counts = {label: 0 for label in nih.NIHChestXRay.LABELS}\n",
        "    for _, labels_batch in loader:\n",
        "        for i, label in enumerate(nih.NIHChestXRay.LABELS):\n",
        "            counts[label] += labels_batch[:, i].sum().item()\n",
        "    return counts\n",
        "\n",
        "label_counts = count_labels(train_loader)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(label_counts.keys(), label_counts.values())\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Label Distribution in Training Set\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaders: train=400, val=50, test=50\n",
            "Disease labels: ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Data Preprocessing Steps\n",
        "\n",
        "The NIH chest X-ray images undergo several preprocessing steps before being fed into our models:\n",
        "\n",
        "1. **Resizing**: All images are resized to 224×224 pixels to match the input size requirement of the Vision Transformer models.\n",
        "\n",
        "2. **Normalization**: Images are normalized using ImageNet mean and standard deviation values (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) to ensure consistent input scaling.\n",
        "\n",
        "3. **Data Augmentation**: For training data, we apply the following augmentations to increase model robustness:\n",
        "   - Random horizontal flips\n",
        "   - Random rotations (±10 degrees)\n",
        "   - Random brightness and contrast adjustments\n",
        "\n",
        "4. **Class Balancing**: Due to the imbalanced nature of the dataset (some conditions are much rarer than others), we employ class weighting during training to prevent the model from ignoring minority classes.\n",
        "\n",
        "5. **Binary Label Creation**: For the binary classifier, we create a new target where any image with at least one finding (not labeled as \"No Finding\") is considered positive.\n",
        "\n",
        "**Note**: The actual preprocessing implementation details can be found in the `NIH_ChestXRay_Dataset_Module.py` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Model Implementation (10%)\n",
        "\n",
        "## 2.1 Hierarchical Model Architecture\n",
        "\n",
        "Our approach uses a hierarchical architecture with two specialized Vision Transformer (ViT) models:\n",
        "\n",
        "1. **Binary Classifier**: Determines if an X-ray contains any pathological finding (abnormal vs. normal)\n",
        "2. **Disease Classifier**: Identifies specific diseases only when the binary classifier detects an abnormality\n",
        "\n",
        "This architecture mimics radiologist workflow, where they first detect the presence of any abnormality before characterizing specific conditions. This approach may lead to better performance and efficiency by allowing each model to specialize in its specific task.\n",
        "\n",
        "## 2.2 Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr35DhSgd8Eq"
      },
      "source": [
        "# Create binary classifier model\n",
        "binary_model = nih_hvit.ViTBinaryClassifier()\n",
        "binary_model.to(device)\n",
        "\n",
        "# Create multi-label disease classifier model\n",
        "disease_model = nih_hvit.ViTDiseaseClassifier(num_labels=len(disease_labels), labels=disease_labels)\n",
        "disease_model.to(device)\n",
        "\n",
        "# Binary model parameters\n",
        "binary_params = sum(p.numel() for p in binary_model.parameters())\n",
        "print(f\"Binary model parameters: {binary_params:,}\")\n",
        "\n",
        "# Disease model parameters\n",
        "disease_params = sum(p.numel() for p in disease_model.parameters())\n",
        "print(f\"Disease model parameters: {disease_params:,}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3 Model Architecture Details\n",
        "\n",
        "### 2.3.1 Binary Classifier\n",
        "\n",
        "The binary classifier model is based on a pre-trained Vision Transformer (ViT) model. It consists of:\n",
        "\n",
        "- **Base Model**: Pre-trained ViT-B/16 model from the `timm` library, which uses 16×16 patches and has been pre-trained on ImageNet\n",
        "- **Adaptation Layer**: A custom head replaces the original classification head to adapt the model for binary classification\n",
        "- **Output**: A single sigmoid output representing the probability of any finding being present\n",
        "\n",
        "### 2.3.2 Disease Classifier\n",
        "\n",
        "The disease classifier model is also based on a pre-trained Vision Transformer, but adapted for multi-label classification:\n",
        "\n",
        "- **Base Model**: Pre-trained ViT-B/16 model from the `timm` library\n",
        "- **Adaptation Layer**: A custom multi-label classification head with 14 outputs (one for each disease)\n",
        "- **Output**: Multiple sigmoid outputs representing the probability of each specific disease\n",
        "\n",
        "### 2.3.3 Inference Flow\n",
        "\n",
        "During inference, the process follows these steps:\n",
        "1. The input X-ray image is first passed through the binary classifier\n",
        "2. If the binary classifier predicts a finding (score above threshold), the image is passed to the disease classifier\n",
        "3. The disease classifier then predicts the probabilities of specific diseases\n",
        "4. If the binary classifier predicts no finding, we skip the disease classifier and return all zeros for disease probabilities\n",
        "\n",
        "This hierarchical approach potentially improves efficiency and accuracy by specializing each model for its specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Methods (5%)\n",
        "\n",
        "## 3.1 Training Strategy\n",
        "\n",
        "We train the binary and disease classifiers separately to allow each model to specialize in its specific task:\n",
        "\n",
        "1. **Binary Classifier Training**:\n",
        "   - Trained to differentiate between normal X-rays (\"No Finding\") and abnormal ones (any disease present)\n",
        "   - Uses binary cross-entropy loss with class weighting to handle the imbalance\n",
        "   - We employ the AdamW optimizer with a learning rate of 1e-4 and weight decay of 1e-5\n",
        "   - Learning rate is scheduled using cosine annealing\n",
        "\n",
        "2. **Disease Classifier Training**:\n",
        "   - Trained to identify specific diseases in abnormal X-rays\n",
        "   - Uses multi-label binary cross-entropy loss (independent binary classifier for each disease)\n",
        "   - Also employs AdamW optimizer with similar hyperparameters\n",
        "   - Uses the same learning rate scheduler\n",
        "\n",
        "## 3.2 Evaluation Metrics\n",
        "\n",
        "We use the following metrics to evaluate our models:\n",
        "\n",
        "1. **Area Under the ROC Curve (AUC)**: Primary metric for both binary and multi-label classification\n",
        "2. **Accuracy**: For the binary classifier\n",
        "3. **Per-class AUC**: To evaluate performance on each specific disease\n",
        "4. **Mean AUC**: Average AUC across all disease classes\n",
        "\n",
        "## 3.3 Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT26LvIGd8Eq"
      },
      "source": [
        "# Loss functions\n",
        "binary_criterion = torch.nn.BCEWithLogitsLoss()\n",
        "disease_criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Optimizers\n",
        "binary_optimizer = AdamW(binary_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "disease_optimizer = AdamW(disease_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "# Learning rate schedulers\n",
        "binary_scheduler = CosineAnnealingLR(binary_optimizer, T_max=5)\n",
        "disease_scheduler = CosineAnnealingLR(disease_optimizer, T_max=5)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Experiments and Results (10%)\n",
        "\n",
        "## 4.1 Binary Classifier Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcaIlnzLd8Eq"
      },
      "source": [
        "# Training Binary Classifier\n",
        "num_epochs = 5  # Adjust as needed\n",
        "binary_train_losses = []\n",
        "binary_val_losses = []\n",
        "binary_val_aucs = []\n",
        "binary_val_accs = []\n",
        "best_binary_auc = 0.0\n",
        "\n",
        "print(f\"Training binary classifier for {num_epochs} epochs...\")\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Train\n",
        "    train_loss = nih_hvit.train_binary_model(binary_model, train_loader, binary_criterion, binary_optimizer, device, epoch)\n",
        "    binary_train_losses.append(train_loss)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_auc, val_acc = nih_hvit.validate_binary_model(binary_model, val_loader, binary_criterion, device)\n",
        "    binary_val_losses.append(val_loss)\n",
        "    binary_val_aucs.append(val_auc)\n",
        "    binary_val_accs.append(val_acc)\n",
        "\n",
        "    # Update learning rate\n",
        "    binary_scheduler.step()\n",
        "\n",
        "    # Save best model\n",
        "    if val_auc > best_binary_auc:\n",
        "        best_binary_auc = val_auc\n",
        "        torch.save(binary_model.state_dict(), f'binary_model_epoch_{epoch+1}_auc_{val_auc:.3f}.pt')\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(binary_train_losses, label='Train Loss')\n",
        "plt.plot(binary_val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Binary Classifier Training and Validation Loss')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(binary_val_aucs, label='Validation AUC')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('AUC')\n",
        "plt.legend()\n",
        "plt.title('Binary Classifier Validation AUC')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(binary_val_accs, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Binary Classifier Validation Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1.1 Binary Classifier Results Summary\n",
        "\n",
        "**[Placeholder - to be filled after training]**\n",
        "\n",
        "Summary of the binary classifier performance including:\n",
        "- Final validation AUC: [value]\n",
        "- Final validation accuracy: [value]\n",
        "- Training convergence observations\n",
        "- Key insights from loss and metrics curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 Disease Classifier Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08AavD9Od8Er"
      },
      "source": [
        "# Training Disease Classifier\n",
        "num_epochs = 5  # Adjust as needed\n",
        "disease_train_losses = []\n",
        "disease_val_losses = []\n",
        "disease_val_aucs = []\n",
        "best_disease_auc = 0.0\n",
        "\n",
        "print(f\"Training disease classifier for {num_epochs} epochs...\")\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Train\n",
        "    train_loss = nih_hvit.train_multilabel_model(disease_model, train_loader, disease_criterion, disease_optimizer, device, epoch)\n",
        "    disease_train_losses.append(train_loss)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_auc, class_aucs = nih_hvit.validate_multilabel_model(disease_model, val_loader, disease_criterion, device, disease_labels)\n",
        "    disease_val_losses.append(val_loss)\n",
        "    disease_val_aucs.append(val_auc)\n",
        "\n",
        "    # Update learning rate\n",
        "    disease_scheduler.step()\n",
        "\n",
        "    # Save best model\n",
        "    if val_auc > best_disease_auc:\n",
        "        best_disease_auc = val_auc\n",
        "        torch.save(disease_model.state_dict(), f'disease_model_epoch_{epoch+1}_auc_{val_auc:.3f}.pt')\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}\")\n",
        "    print(\"Class AUCs:\")\n",
        "    for label, auc in class_aucs.items():\n",
        "        print(f\"  {label}: {auc:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(disease_train_losses, label='Train Loss')\n",
        "plt.plot(disease_val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Disease Classifier Training and Validation Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(disease_val_aucs, label='Validation AUC')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('AUC')\n",
        "plt.legend()\n",
        "plt.title('Disease Classifier Validation AUC')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot AUCs for last epoch\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(class_aucs.keys(), class_aucs.values())\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('AUC')\n",
        "plt.title('Disease Classifier Validation AUC by Class')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2.1 Disease Classifier Results Summary\n",
        "\n",
        "**[Placeholder - to be filled after training]**\n",
        "\n",
        "Summary of the disease classifier performance including:\n",
        "- Final mean validation AUC: [value]\n",
        "- Best and worst performing disease classes\n",
        "- Training convergence observations\n",
        "- Key insights from per-class performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3 Hierarchical Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3OeAeFld8Er"
      },
      "source": [
        "# Evaluate hierarchical model\n",
        "print(\"Evaluating hierarchical model on test set...\")\n",
        "test_results = nih_hvit.test_hierarchical_model(binary_model, disease_model, test_loader, device, disease_labels)\n",
        "\n",
        "print(f\"Binary classifier test results:\")\n",
        "print(f\"  AUC: {test_results['binary_auc']:.4f}\")\n",
        "print(f\"  Accuracy: {test_results['binary_accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\nDisease classifier test results:\")\n",
        "print(f\"  Mean AUC: {test_results['mean_disease_auc']:.4f}\")\n",
        "print(\"  AUC by class:\")\n",
        "for label, auc in test_results['disease_aucs'].items():\n",
        "    print(f\"    {label}: {auc:.4f}\")\n",
        "\n",
        "# Plot disease AUCs\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(test_results['disease_aucs'].keys(), test_results['disease_aucs'].values())\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('AUC')\n",
        "plt.title('Test AUC by Disease Class')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3.1 Hierarchical Model Test Results\n",
        "\n",
        "**[Placeholder - to be filled after evaluation]**\n",
        "\n",
        "Summary of the hierarchical model performance on the test set including:\n",
        "- Binary classifier test AUC and accuracy\n",
        "- Disease classifier mean test AUC\n",
        "- Per-disease AUC analysis\n",
        "- Key insights about the hierarchical approach effectiveness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.4 Visualizing Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIJ4GwPOd8Er"
      },
      "source": [
        "# Visualize predictions\n",
        "print(\"Visualizing example predictions from hierarchical model:\")\n",
        "nih_hvit.visualize_hierarchical_predictions(binary_model, disease_model, test_loader, device, disease_labels, num_examples=5)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4.1 Qualitative Analysis of Predictions\n",
        "\n",
        "**[Placeholder - to be filled after running visualization]**\n",
        "\n",
        "Analysis of the example predictions including:\n",
        "- Observations about model confidence\n",
        "- Cases where binary classifier and disease classifier align/disagree\n",
        "- Potential failure modes identified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.5 Comparison with Single Model Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB3StwzUd8Er"
      },
      "source": [
        "# Load comparison results (replace with actual results after experiments)\n",
        "comparison_data = {\n",
        "    'Metric': ['Mean AUC', 'Pneumonia AUC', 'Effusion AUC', 'Cardiomegaly AUC', 'Atelectasis AUC', 'Training Time', 'Inference Time'],\n",
        "    'Single Model': [0.0, 0.0, 0.0, 0.0, 0.0, '0 min', '0ms'],  # Placeholder values\n",
        "    'Hierarchical Model': [0.0, 0.0, 0.0, 0.0, 0.0, '0 min', '0ms']  # Placeholder values\n",
        "}\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df.set_index('Metric', inplace=True)\n",
        "comparison_df"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5.1 Performance Comparison Analysis\n",
        "\n",
        "**[Placeholder - to be filled after comparison]**\n",
        "\n",
        "Analysis of the hierarchical model compared to the single model approach including:\n",
        "- Overall performance differences\n",
        "- Performance on specific diseases\n",
        "- Computational efficiency comparison\n",
        "- Trade-offs between approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRLgdXcXd8Er"
      },
      "source": [
        "# 5. Conclusion and Future Work\n",
        "\n",
        "This notebook demonstrated a hierarchical approach to chest X-ray classification using two Vision Transformer models. The binary classifier first determines if there's any pathological finding, and then the multi-label classifier identifies specific conditions only when the binary classifier detects a finding.\n",
        "\n",
        "## 5.1 Key Findings\n",
        "\n",
        "**[Placeholder - to be completed after all experiments]**\n",
        "\n",
        "1. **Hierarchical Performance**: \n",
        "   - How does the hierarchical approach compare to the single model?\n",
        "   - What are the benefits and drawbacks?\n",
        "   - Did the approach improve performance on any specific diseases?\n",
        "\n",
        "2. **Clinical Relevance**: The hierarchical approach more closely mimics radiologist workflow, potentially making it more interpretable and clinically relevant.\n",
        "\n",
        "3. **Efficiency Considerations**: While requiring two models, the hierarchical approach may be more computationally efficient at inference time since the more complex disease classifier only runs on images with detected findings.\n",
        "\n",
        "## 5.2 Limitations\n",
        "\n",
        "**[Placeholder - to be completed after experiments]**\n",
        "\n",
        "- Limitations of the current approach\n",
        "- Dataset limitations\n",
        "- Challenges encountered\n",
        "\n",
        "## 5.3 Future Work\n",
        "\n",
        "1. **Joint Training**: Exploring end-to-end training approaches where both models are trained jointly with a shared loss function.\n",
        "\n",
        "2. **Confidence Calibration**: Improving the calibration of confidence scores, especially for the binary classifier which acts as a gatekeeper.\n",
        "\n",
        "3. **Attention Visualization**: Implementing visualization of attention maps for both models to improve interpretability.\n",
        "\n",
        "4. **Clinical Validation**: Validating the hierarchical approach against radiologist performance and clinical outcomes.\n",
        "\n",
        "5. **Model Optimization**: Exploring different architectures and hyperparameters to further improve performance."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}